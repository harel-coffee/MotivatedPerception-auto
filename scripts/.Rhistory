correlationPlot = as.data.frame(cbind(NeuralBias, intSlope))
# Plot behavioral bias
plot.prob.behav = ggplot(data = correlationPlot, aes(x = NeuralBias, y = intSlope)) +
geom_point() +
geom_smooth(method='lm',se=FALSE, colour="black") +
theme(legend.position="none",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.text.x  = element_text(size=13,color="black"),
axis.text.y  = element_text(size=13,color="black"),
axis.line = element_line(colour = "black"),
strip.background = element_blank(),
strip.text.x = element_text(face = "bold"),
plot.title = element_text(face = "plain", size = (15))) +
coord_cartesian(ylim=c(-1.5, 5)) +
ylab("Motivational Bias") + xlab("Neural Bias")
confint.default(rb_lm)
summary(rb_lm)
# Clear workspace
rm(list = ls())
# Load helper functions
source('helper_functions.R')
# Import libraries
packages = c("MASS","sfsmisc","tidyr","dplyr","ggplot2","lme4","lmerTest","Hmisc","car","lmtest","Rarity","cowplot")
ipak(packages)
# Redo long calculations
redo_calc = 0;
# Read data
AllData = read.csv("../data/AllData.csv")
# Convert to factors
AllData$Sub = as.factor(AllData$Sub)
AllData$Pred = as.factor(AllData$Pred)
AllData$Want2See = as.factor(AllData$Want2See)
AllData$Con_Rev = factor(AllData$Con, levels = c('Coop','Comp'))
AllData_ValidTrials = filter(AllData, !(is.na(Choice)))
# Load psychometric results (see Fig. 2 code)
load("long_calc/ConditionxBet.Rda")
## Median split participants
intSlope = unlist(coef(res)$Sub$`ConCoop:Pred1`)
SubBias = as.data.frame(intSlope)
SubBias$Sub = unique(AllData$Sub)
SubBias$medianBehave = SubBias$intSlope > median(SubBias$intSlope)
BiasedData =  subset(AllData_ValidTrials, Sub %in% SubBias$Sub[SubBias$medianBehav == "TRUE"])
UnbiasedData = subset(AllData_ValidTrials, Sub %in% SubBias$Sub[SubBias$medianBehav == "FALSE"])
if (redo_calc) {
res.prob = lmer(Prob ~ Cat_n_z  + Con * Pred + (Con * Pred |Sub), AllData_ValidTrials)
res.prob.bias = lmer(Prob ~ Cat_n_z  + Con * Pred + (Con * Pred |Sub), BiasedData)
res.prob.unbias = lmer(Prob ~ Cat_n_z  + Con * Pred + (Con * Pred |Sub), UnbiasedData)
save(res.prob, res.prob.bias, res.prob.unbias, file="long_calc/NeuralBias.Rda")
} else {
load("long_calc/NeuralBias.Rda")
}
AllData_ValidTrials = full_join(AllData_ValidTrials, SubBias)
summary(res.prob)
res.int.con = lmer(Prob ~ Cat_n_z  + Con * Pred * intSlope + (Con * Pred|Sub), AllData_ValidTrials)
summary(res.int.con)
# High Bias participants
summary(res.prob.bias)
# Low Bias Participants
summary(res.prob.unbias)
# Bias Plot
plot.prob.bias = ggplot(BiasedData, aes(x=Cat_n,y=Prob,color = Pred)) +
stat_summary(fun.y=mean,geom="point",size=2) +
stat_summary(fun.data = mean_cl_normal, geom = "errorbar",width=1,
fun.args = list(mult = 1)) +
theme(legend.position="none",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.text.x  = element_text(size=13,color="black"),
axis.text.y  = element_text(size=13,color="black"),
axis.title.x = element_text(size=15),
axis.title.y = element_text(size=13),
strip.background = element_blank(),
strip.text.x = element_text(face = "plain", size = 13)) +
xlab("% Scene") + ylab("Classifier Prob(Scene)") +
facet_grid(~Con_Rev, labeller=labeller(Con_Rev = c("Coop" = "Cooperation","Comp" = "Competition"))) +
scale_colour_manual(values=myPalette) +
ggtitle("High Bias")
# Unbias plot
plot.prob.unbias = ggplot(UnbiasedData, aes(x=Cat_n,y=Prob,color = Pred)) +
stat_summary(fun.y=mean,geom="point",size=2) +
stat_summary(fun.data = mean_cl_normal, geom = "errorbar",width=1,
fun.args = list(mult = 1)) +
theme(legend.position="none",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.text.x  = element_text(size=13,color="black"),
axis.text.y  = element_text(size=13,color="black"),
axis.title.x = element_text(size=15),
axis.title.y = element_text(size=13),
strip.background = element_blank(),
strip.text.x = element_text(face = "plain", size = 13)) +
xlab("% Scene") + ylab("Classifier Prob(Scene)") +
facet_grid(~Con_Rev, labeller=labeller(Con_Rev = c("Coop" = "Cooperation","Comp" = "Competition"))) +
scale_colour_manual(values=myPalette) +
ggtitle("Low Bias")
NeuralBias = NULL
for (s in unique(AllData$Sub)){
thisData = NULL
this_res = lm(Prob ~ Cat_n + Con * Pred, data = subset(AllData_ValidTrials, Sub == s))
this_coef = coef(this_res)["ConCoop:Pred1"]
thisData$NeuralBias = this_coef
NeuralBias = rbind(NeuralBias,thisData)
}
NeuralBias = as.numeric(NeuralBias)
cor.test(NeuralBias, intSlope)
# Robust Regression
rb_lm = rlm(intSlope ~ NeuralBias)
summary(rb_lm)
f.robftest(rb_lm , var = "NeuralBias")
correlationPlot = as.data.frame(cbind(NeuralBias, intSlope))
# Plot behavioral bias
plot.prob.behav = ggplot(data = correlationPlot, aes(x = NeuralBias, y = intSlope)) +
geom_point() +
geom_smooth(method='lm',se=FALSE, colour="black") +
theme(legend.position="none",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.text.x  = element_text(size=13,color="black"),
axis.text.y  = element_text(size=13,color="black"),
axis.line = element_line(colour = "black"),
strip.background = element_blank(),
strip.text.x = element_text(face = "bold"),
plot.title = element_text(face = "plain", size = (15))) +
coord_cartesian(ylim=c(-1.5, 5)) +
ylab("Motivational Bias") + xlab("Neural Bias")
# Load model parameters
full.model.subj_parm = read.csv("../data/model_outputs/subject_parms/simpleFull_subjparms.csv")
full.model.subj_parm$Sub = as.factor(full.model.subj_parm$Sub)
full.model.subj_parm = left_join(full.model.subj_parm,SubBias)
full.model.subj_parm$NeuralBias = NeuralBias
# Run GLM
lm.VVS = summary(lm(scale(NeuralBias) ~ scale(z) + scale(drift_bias), full.model.subj_parm))
lm.VVS
lm.VVS.coef = lm.VVS$coefficients
test = lm(scale(NeuralBias) ~ scale(z) + scale(drift_bias), full.model.subj_parm)
confint(test, method = "Wald")
# Clear workspace
rm(list = ls())
# Load helper functions
source('helper_functions.R')
# Import libraries
packages = c("tidyr","dplyr","ggplot2","lme4","lmerTest","Hmisc","car","lmtest","Rarity","cowplot")
ipak(packages)
# Redo long calculations
redo_calc = 0;
# Read data
AllData = read.csv("../data/AllData.csv")
# Convert to factors
AllData$Sub = as.factor(AllData$Sub)
AllData$Pred = as.factor(AllData$Pred)
AllData$Want2See = as.factor(AllData$Want2See)
AllData$Con_Rev = factor(AllData$Con, levels = c('Coop','Comp'))
# Load psychometric results (see Fig. 2 code)
load("long_calc/ConditionxBet.Rda")
# Extract random slope of the interaction
intSlope = unlist(coef(res)$Sub$`ConCoop:Pred1`)
# Create datafrom for each subject's bias, and order in descending order
SubBias = as.data.frame(intSlope)
SubBias$Sub = unique(AllData$Sub)
SubBias = SubBias[order(-SubBias$intSlope), ]
full.model.parm = read.csv("../data/model_outputs/subject_parms/SeparateDriftRate_parms.csv")
# Only keep paramters at the subject level
full.model.subj_parm = filter(full.model.parm, grepl('subj', X)) %>%
select(X,mean)
# Clear workspace
rm(list = ls())
# Load helper functions
source('helper_functions.R')
# Import libraries
packages = c("tidyr","dplyr","ggplot2","lme4","lmerTest","Hmisc","car","lmtest","Rarity","cowplot")
ipak(packages)
# Redo long calculations
redo_calc = 0;
# Read data
AllData = read.csv("../data/AllData.csv")
# Convert to factors
AllData$Sub = as.factor(AllData$Sub)
AllData$Pred = as.factor(AllData$Pred)
AllData$Want2See = as.factor(AllData$Want2See)
AllData$Con_Rev = factor(AllData$Con, levels = c('Coop','Comp'))
# Load psychometric results (see Fig. 2 code)
load("long_calc/ConditionxBet.Rda")
# Extract random slope of the interaction
intSlope = unlist(coef(res)$Sub$`ConCoop:Pred1`)
# Create datafrom for each subject's bias, and order in descending order
SubBias = as.data.frame(intSlope)
SubBias$Sub = unique(AllData$Sub)
SubBias = SubBias[order(-SubBias$intSlope), ]
full.model.parm = read.csv("../data/model_outputs/subject_parms/SeparateDriftRate_parms.csv")
# Only keep paramters at the subject level
full.model.subj_parm = filter(full.model.parm, grepl('subj', X)) %>%
select(X,mean)
# Only keep v parameter
v_bias = filter(full.model.subj_parm, grepl('v_', X)) %>%
separate("X",sep = c(1,7),into = c("parm","foo","foo2")) %>%
separate("foo2", sep = "\\.", into = c("mot1","mot2","cat1","cat2","Sub")) %>%
separate("cat2", into = c("cat2","foo2")) %>%
unite(mot,c(mot1,mot2)) %>%
unite(cat,c(cat1,cat2)) %>%
unite(v_cond,c(mot,cat)) %>%
select(Sub,mean,v_cond) %>%
spread(v_cond,mean) %>%
transmute(Sub = Sub,
`v_-5_0` = `1_0_-5_0` - `-1_0_-5_0`,
`v_-1_5` = `1_0_-1_5` - `-1_0_-1_5`,
`v_-1_0` = `1_0_-1_0` - `-1_0_-1_0`,
`v_-0_5` = `1_0_-0_5` - `-1_0_-0_5`,
`v_0_0` = `1_0_0_0` - `-1_0_0_0`,
`v_0_5` = `1_0_0_5` - `-1_0_0_5`,
`v_1_0` = `1_0_1_0` - `-1_0_1_0`,
`v_1_5` = `1_0_1_5` - `-1_0_1_5`,
`v_5_0` = `1_0_5_0` - `-1_0_5_0`)
v_bias_tidy = v_bias %>%
gather(type, value, c(2:10)) %>%
separate(type, sep = "_", into = c("parm", "cat1", "cat2")) %>%
unite(cat,c(cat1,cat2), sep = "")
v_bias_tidy$cat = as.numeric(v_bias_tidy$cat) + 50
summary(lmer(value ~ poly(cat,2) + (poly(cat,2)|Sub), data = v_bias_tidy))
summary(lmer(value ~ poly(cat,2) + (poly(cat,2)|Sub), data = subset(v_bias_tidy, (cat > 10) & (cat < 90))))
summary(lmer(mean ~ mot1 + scale(cat) + (mot1 + scale(cat) |Sub), data = v_bias))
# Clear workspace
rm(list = ls())
# Load helper functions
source('helper_functions.R')
# Import libraries
packages = c("tidyr","dplyr","ggplot2","lme4","lmerTest","Hmisc","car","lmtest","Rarity","cowplot")
ipak(packages)
# Redo long calculations
redo_calc = 0;
# Read data
AllData = read.csv("../data/AllData.csv")
# Convert to factors
AllData$Sub = as.factor(AllData$Sub)
AllData$Pred = as.factor(AllData$Pred)
AllData$Want2See = as.factor(AllData$Want2See)
AllData$Con_Rev = factor(AllData$Con, levels = c('Coop','Comp'))
# Load psychometric results (see Fig. 2 code)
load("long_calc/ConditionxBet.Rda")
# Extract random slope of the interaction
intSlope = unlist(coef(res)$Sub$`ConCoop:Pred1`)
# Create datafrom for each subject's bias, and order in descending order
SubBias = as.data.frame(intSlope)
SubBias$Sub = unique(AllData$Sub)
SubBias = SubBias[order(-SubBias$intSlope), ]
full.model.parm = read.csv("../data/model_outputs/subject_parms/SeparateDriftRate_parms.csv")
# Only keep paramters at the subject level
full.model.subj_parm = filter(full.model.parm, grepl('subj', X)) %>%
select(X,mean)
# Only keep v parameter
v_bias = filter(full.model.subj_parm, grepl('v_', X)) %>%
separate("X",sep = c(1,7),into = c("parm","foo","foo2")) %>%
separate("foo2", sep = "\\.", into = c("mot1","mot2","cat1","cat2","Sub")) %>%
separate("cat2", into = c("cat2","foo2")) %>%
unite(mot,c(mot1,mot2)) %>%
unite(cat,c(cat1,cat2)) %>%
unite(v_cond,c(mot,cat)) %>%
select(Sub,mean,v_cond) %>%
spread(v_cond,mean) %>%
transmute(Sub = Sub,
`v_-5_0` = `1_0_-5_0` - `-1_0_-5_0`,
`v_-1_5` = `1_0_-1_5` - `-1_0_-1_5`,
`v_-1_0` = `1_0_-1_0` - `-1_0_-1_0`,
`v_-0_5` = `1_0_-0_5` - `-1_0_-0_5`,
`v_0_0` = `1_0_0_0` - `-1_0_0_0`,
`v_0_5` = `1_0_0_5` - `-1_0_0_5`,
`v_1_0` = `1_0_1_0` - `-1_0_1_0`,
`v_1_5` = `1_0_1_5` - `-1_0_1_5`,
`v_5_0` = `1_0_5_0` - `-1_0_5_0`)
v_bias_tidy = v_bias %>%
gather(type, value, c(2:10)) %>%
separate(type, sep = "_", into = c("parm", "cat1", "cat2")) %>%
unite(cat,c(cat1,cat2), sep = "")
v_bias_tidy$cat = as.numeric(v_bias_tidy$cat) + 50
summary(lmer(value ~ poly(cat,2) + (poly(cat,2)|Sub), data = v_bias_tidy))
summary(lmer(value ~ poly(cat,2) + (poly(cat,2)|Sub), data = subset(v_bias_tidy, (cat > 10) & (cat < 90))))
# Moderation
v_bias = filter(full.model.subj_parm, grepl('v_', X)) %>%
separate("X",sep = c(1,7),into = c("parm","foo","foo2")) %>%
separate("foo2", sep = "\\.", into = c("mot1","mot2","cat1","cat2","Sub")) %>%
separate("cat2", into = c("cat2","foo2")) %>%
dplyr::select(Sub,parm,mot1,cat1,cat2,mean) %>%
unite(cat,c(cat1,cat2), sep = '')
v_bias$cat = as.numeric(v_bias$cat)
v_bias$Sub = factor(v_bias$Sub)
v_bias$mot1 = factor(v_bias$mot1)
v_bias = full_join(SubBias, v_bias)
v_bias$HighBias = v_bias$intSlope > median(v_bias$intSlope)
v_bias$medianBehav = ifelse(v_bias$HighBias, "HighBias", "LowBias")
summary(lmer(mean ~ mot1 + scale(cat) + (mot1 + scale(cat) |Sub), data = v_bias))
summary(lmer(mean ~ mot1 + intSlope*scale(cat) + (mot1 + intSlope*scale(cat) |Sub), data = v_bias))
summary(lmer(mean ~mot1 + cat + (mot1 + cat |Sub), data = subset(v_bias, medianBehav == "HighBias")))
summary(lmer(mean ~mot1 + cat + (mot1 + cat |Sub), data = subset(v_bias, medianBehav == "LowBias")))
summary(lmer(mean ~ intSlope*mot1 + cat + (intSlope*mot1 |Sub), data = v_bias))
ggplot() +
stat_summary(data = v_bias, aes(x=cat,y=mean,color = mot1),
fun.y=mean,geom="point",size=2.5) +
stat_summary(data = v_bias, aes(x=cat,y=mean,color = mot1),
fun.data = mean_cl_normal, geom = "errorbar",width=1,
fun.args = list(mult = 1)) +
theme(legend.position="none",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.text.x  = element_text(size=13,color="black"),
axis.text.y  = element_text(size=13,color="black"),
axis.title.x = element_text(size=15),
axis.title.y = element_text(size=15),
strip.background = element_blank(),
strip.text.x = element_text(face = "bold", size = 15)) +
xlab("% Scene") + ylab("Drift Rate") +
facet_grid(~medianBehav) +
#facet_grid(~medianBehav, labeller=labeller(Con_Rev = c("Coop" = "Cooperation","Comp" = "Competition"))) +
scale_colour_manual(values=myPalette)
test = lmer(mean ~ mot1 + scale(cat) + (mot1 + scale(cat) |Sub), data = v_bias)
summary(test)
test = lmer(mean ~ mot1 + intSlope*scale(cat) + (mot1 + intSlope*scale(cat) |Sub), data = v_bias)
summary(test)
confint(test, method = "Wald")
summary(lmer(mean ~ mot1 + scale(cat) + (mot1 + scale(cat) |Sub), data = v_bias))
test = lmer(mean ~ mot1 + scale(cat) + (mot1 + scale(cat) |Sub), data = v_bias)
summary(test)
confint(test, method = "Wald")
summary(lmer(mean ~ mot1 + intSlope*scale(cat) + (mot1 + intSlope*scale(cat) |Sub), data = v_bias))
summary(lmer(mean ~ mot1 + scale(cat) + (mot1 + scale(cat) |Sub), data = v_bias))
summary(lmer(mean ~ intSlope*mot1 + cat + (intSlope*mot1 |Sub), data = v_bias))
summary(lmer(mean ~ mot1 + scale(cat) + (mot1 + scale(cat) |Sub), data = v_bias))
test = lmer(mean ~ mot1 + scale(cat) + (mot1 + scale(cat) |Sub), data = v_bias)
confint(test, method = "Wald")
# Clear workspace
rm(list = ls())
# Load helper functions
source('helper_functions.R')
# Import libraries
packages = c("tidyr","dplyr","ggplot2","lme4","lmerTest","Hmisc","car","lmtest","Rarity","cowplot","MASS",'sfsmisc')
ipak(packages)
# Redo long calculations
redo_calc = 0;
# Read data
AllData = read.csv("../data/AllData_inlab.csv")
# Convert to factors
AllData$Sub = as.factor(AllData$Sub)
AllData$Pred = as.factor(AllData$Pred)
AllData$Want2See = as.factor(AllData$Want2See)
AllData$Con_Rev = factor(AllData$Con, levels = c('Coop','Comp'))
AllData$Cat_n_z = as.numeric((scale(AllData$Cat_n)))
# Cooperation Condition: Does motivation bias participants' perceptual judgments?
thisData = subset(AllData, Con == "Coop")
summary(glmer(Choice ~ Cat_n_z + Pred + (Pred |Sub), thisData, family = binomial(link="probit")))
# Competition Condition: Does motivation bias participants' perceptual judgments?
thisData = subset(AllData, Con == "Comp")
summary(glmer(Choice ~ Cat_n_z + Pred + (Pred |Sub), thisData, family = binomial(link="probit")))
# Condition x Bet Interaction
if (redo_calc) {
res = glmer(Choice ~ Cat_n_z + Con * Pred + (Con * Pred|Sub), AllData,
family = binomial(link="probit"), control = glmerControl(calc.derivs = FALSE))
save(res,file="long_calc/ConditionxBet_Inlab.Rda")
} else {
load("long_calc/ConditionxBet_Inlab.Rda")
}
summary(res)
thisData = AllData
thisData$Pred = recode(thisData$Pred,"0='Face';1='Scene'")
# Run GLM (for visualization only, do not use for inference)
res.glm = glm(Choice ~ Cat_n + Con_Rev * Pred, thisData, family = binomial(link="probit"))
# Create predicted dataset
pred.data = data.frame(Cat_n = rep(seq(0, 100, len = 101),4),
Con_Rev = c(rep("Coop",202),rep("Comp",202)),
Pred = c(rep("Face",101),rep("Scene",101),rep("Face",101),rep("Scene",101))
)
pred.data$Choice = predict.glm(res.glm,pred.data,type = "response")
# Compute Subject Average
sub_avg = group_by(thisData,Sub,Con_Rev,Cat_n,Pred) %>%
summarise(Avg = mean(Choice, na.rm=T), SEM = sem(Choice))
# Plot group average with fit
plot.behav = ggplot() +
stat_summary(data = sub_avg, aes(x=Cat_n,y=Avg,color = Pred),
fun.y=mean,geom="point",size=3, alpha = 0.75) +
stat_summary(data = sub_avg, aes(x=Cat_n,y=Avg,color = Pred),
fun.data = mean_cl_normal, geom = "errorbar",width=1,
fun.args = list(mult = 1)) +
geom_line(data = pred.data, aes(x=Cat_n,y=Choice,color= Pred),size=1, alpha = 0.8) +
theme(legend.position="none",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
axis.text.x  = element_text(size=13,color="black"),
axis.text.y  = element_text(size=13,color="black"),
axis.title.x = element_text(size=15),
axis.title.y = element_text(size=15),
strip.background = element_blank(),
strip.text.x = element_text(face = "bold", size = 15)) +
xlab("% Scene") + ylab("P(Respond Scene)") +
facet_grid(~Con_Rev, labeller=labeller(Con_Rev = c("Coop" = "Cooperation","Comp" = "Competition"))) +
scale_colour_manual(values=myPalette)
# Extract random slope of the interaction
intSlope = unlist(coef(res)$Sub$`ConCoop:Pred1`)
# Create datafrom for each subjec'ts bias, and order in descending order
SubBias = as.data.frame(intSlope)
SubBias$Sub = unique(AllData$Sub)
SubBias = SubBias[order(-SubBias$intSlope), ]
plot.behavbias = ggplot(data=SubBias, aes(c(1:28), y=intSlope)) +
geom_bar(stat="identity") +
theme(legend.position="none",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.text.x  = element_blank(),
axis.text.y  = element_text(size=14,color="black"),
axis.line.x = element_blank(),
axis.ticks.x = element_blank(),
strip.background = element_blank(),
strip.text.x = element_text(face = "bold")) +
xlab("Participant") + ylab("Motivational Bias") +
scale_y_continuous(breaks=seq(0,4,2)) +
coord_cartesian(ylim=c(-1, 5))
# Calculate performance
performData=subset(AllData,(Cat_n != 50) & !is.na(Choice))
performData = mutate(performData, outcome = (Choice == 1 & Cat_n > 50) | (Choice == 0 & Cat_n < 50))
# Run correlation
dPerform = group_by(performData,Sub) %>%
summarise(avg= sum(outcome)*0.10)
dPerform = left_join(dPerform,SubBias)
# Make performance plot
plot.perform = ggplot(dPerform, aes(intSlope, avg)) +
geom_point() +
geom_smooth(method='rlm',se=FALSE, colour="black") +
theme(legend.position="none",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.text.x  = element_text(size=14,color="black"),
axis.text.y  = element_text(size=14,color="black"),
axis.line = element_line(colour = "black"),
strip.background = element_blank(),
strip.text.x = element_text(face = "bold")) +
xlab("Motivational Bias") +
ylab("Earnings") +
coord_cartesian(ylim=c(8.2, 12.2))
confint.default(rb_lm)
cor.test(dPerform$intSlope, dPerform$avg)
# Robust Regression
rb_lm = rlm(avg ~ intSlope, data = dPerform)
confint.default(rb_lm)
summary(rb_lm)
f.robftest(rb_lm , var = "intSlope")
confint.default(rb_lm)
summary(resCondRT)
# Clear workspace
rm(list = ls())
# Load helper functions
source('helper_functions.R')
# Import libraries
packages = c("tidyr","dplyr","ggplot2","lme4","lmerTest","Hmisc","car","lmtest","Rarity","cowplot")
ipak(packages)
# Redo long calculations
redo_calc = 0;
# Read data
AllData = read.csv("../data/AllData.csv")
# Convert to factors
AllData$Sub = as.factor(AllData$Sub)
AllData$Pred = as.factor(AllData$Pred)
AllData$Want2See = as.factor(AllData$Want2See)
AllData$Con_Rev = factor(AllData$Con, levels = c('Coop','Comp'))
AllData_ValidTrials = filter(AllData, !(is.na(Choice)))
# Load psychometric results (see Fig. 2 code)
load("long_calc/ConditionxBet.Rda")
AllData$Conf = as.numeric(as.character(AllData$Conf))
AllData$RT = as.numeric(as.character(AllData$RT))
AllData$CatDiff = abs(50 - AllData$Cat_n)*2
AllData$ChoiceF = factor(AllData$Choice)
if (redo_calc){
##  MotConRT ##
resMotConRT = lmer(log(RT) ~ MotCon + CatDiff + (MotCon + CatDiff | Sub), AllData, control =lmerControl(calc.derivs = FALSE))
resMotConRT_Face = lmer(log(RT) ~ Want2See + CatDiff + (Want2See + CatDiff | Sub), subset(AllData, ChoiceF == "0"), control = lmerControl(calc.derivs = FALSE))
resMotConRT_Scene = lmer(log(RT) ~ Want2See + CatDiff + (Want2See + CatDiff | Sub), subset(AllData, ChoiceF == "1"), control =lmerControl(calc.derivs = FALSE))
resMotConRT_direct = lmer(log(RT) ~ MotCon + CatDiff + (MotCon + CatDiff |Sub), AllData, control =lmerControl(calc.derivs = FALSE))
## Condition Differences ##
resCondRT = lmer(log(RT) ~ CatDiff + Con + (Con + CatDiff |Sub), AllData, control =lmerControl(calc.derivs = FALSE))
resCondResponseRT = lmer(log(RT) ~ CatDiff + Con * Choice + (Con *  Choice + CatDiff|Sub), AllData, control =lmerControl(calc.derivs = FALSE))
resCondMotRT = lmer(log(RT) ~ CatDiff + Con * Want2See * Choice + (Con * Want2See * Choice + CatDiff|Sub), AllData, control =lmerControl(calc.derivs = FALSE))
sum_resCondMotRT = summary(resCondMotRT)
save(resMotConRT, resMotConRT_direct, resMotConRT_Face, resMotConRT_Scene, resCondRT, resCondMotRT, sum_resCondMotRT, resCondResponseRT, file="long_calc/RTMot.Rda")
}else{
load("long_calc/RTMot.Rda")
}
# MotConRT
summary(resMotConRT_direct)
# MotConRT_Face
summary(resMotConRT_Face)
# MotConRT_Scene
summary(resMotConRT_Scene)
# Main effect of Condition on RT
summary(resCondRT)
# Interaction effect of Condition x Response on RT
summary(resCondResponseRT)
# Interaction effect of Condition X Want2See X Response on RT
sum_resCondMotRT
summary(resCondRT)
confint(resCondRT, method = "Wald")
confint(resCondResponseRT, method = "Wald")
# Interaction effect of Condition X Want2See X Response on RT
sum_resCondMotRT
confint(resCondMotRT, method = "Wald")
