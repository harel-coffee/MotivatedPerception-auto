{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel\n",
    "import numpy as np\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn import image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjIDs = [\"2013\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\",\"2020\",\"2021\",\"2022\",\"2024\", \n",
    "\"2027\",\"2028\",\"2029\",\"2030\",\"2031\",\"2032\",\"2033\",\"2034\",\"2035\",\"2036\",\"2038\",\n",
    "\"2039\",\"2040\",\"2041\",\"2042\",\"2043\",\"2044\",\"2045\",\"2046\",\"2047\"]\n",
    "\n",
    "mask_file = \"vvs\";\n",
    "design = \"TrialBetas_1stImage\"\n",
    "classifier_name = \"log_l1\" # Or 'SVC', 'log_l1', log_l1_50 or log_l2\n",
    "\n",
    "dir_input = \"../../results/TrialClassification/\" + design + \"_zmap\"\n",
    "dir_label = \"../../data/trialclassification/TrialBetas_2ndBet\"\n",
    "\n",
    "#dir_traininput = \"../../results/TrialClassification/TrialBetas_2ndBet_zmap\"\n",
    "#dir_trainlabel = \"../../data/trialclassification/TrialBetas_2ndBet\"\n",
    "\n",
    "dir_traininput =\"../../results/align_native_delete3\"\n",
    "dir_trainlabel =\"../../data/trial_labels_task_delete3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subjID in subjIDs:\n",
    "    print(\"Running Subj: %s\" % subjID)\n",
    "    \n",
    "    #############################################################################\n",
    "    #                     Always train on the same lag                         #\n",
    "    #############################################################################\n",
    "        \n",
    "    # fMRI path\n",
    "    run5_path = dir_traininput + \"/\" + subjID + \"/run5.feat/filtered_func_data.nii.gz\"\n",
    "    run6_path = dir_traininput + \"/\" + subjID + \"/run6.feat/filtered_func_data.nii.gz\"\n",
    "    \n",
    "    # mask path\n",
    "    mask_path = \"../../data/masks/\" + mask_file + \"/\" + subjID + \"_\" + mask_file + \"_3mm.nii.gz\"\n",
    "    \n",
    "    # Labels\n",
    "    label_run5_path = dir_trainlabel + \"/\" + subjID + \"/Add0/run5_label.txt\"\n",
    "    label_run6_path = dir_trainlabel + \"/\" + subjID + \"/Add0/run6_label.txt\"\n",
    "    \n",
    "    # Load labels and make target\n",
    "    run5_labels = np.recfromcsv(label_run5_path, delimiter=\" \")\n",
    "    run5_target = run5_labels['labels']\n",
    "    run5_condition_mask = np.logical_or(run5_labels['labels'] == 1, run5_labels['labels'] == 2)\n",
    "    run5_target = run5_target[run5_condition_mask]\n",
    "    \n",
    "    run6_labels = np.recfromcsv(label_run6_path, delimiter=\" \")\n",
    "    run6_target = run6_labels['labels']\n",
    "    run6_condition_mask = np.logical_or(run6_labels['labels'] == 1, run6_labels['labels'] == 2)\n",
    "    run6_target = run6_target[run6_condition_mask]\n",
    "\n",
    "    # Load MRI data\n",
    "    nifti_masker = NiftiMasker(mask_img=mask_path,standardize=True)\n",
    "    run5_fmri_masked = nifti_masker.fit_transform(run5_path)    \n",
    "    run6_fmri_masked = nifti_masker.fit_transform(run6_path)\n",
    "    \n",
    "    run5_fmri_masked = run5_fmri_masked[run5_condition_mask]\n",
    "    run6_fmri_masked = run6_fmri_masked[run6_condition_mask]\n",
    "        \n",
    "    # Concatenate Runs\n",
    "    combined_runs = np.vstack((run5_fmri_masked,run6_fmri_masked))\n",
    "        \n",
    "    # Concatenate Labels\n",
    "    combined_labels = np.hstack((run5_target,run6_target))\n",
    "    \n",
    "    # Decoder\n",
    "    if classifier_name == \"log_l1\":\n",
    "        print \"Training using log_l1\"\n",
    "        classifier = LogisticRegression(C=1., penalty=\"l1\")  \n",
    "\n",
    "        \n",
    "    # Train\n",
    "    classifier.fit(combined_runs, combined_labels)\n",
    "        \n",
    "    # Create toPrint \n",
    "    AllShifts = np.zeros((0,5));\n",
    "                    \n",
    "    # Initialize variables\n",
    "    task_path = []\n",
    "    task_label_path = []\n",
    "    task_label = []\n",
    "    task_target = []\n",
    "    task_condition_mask = []\n",
    "    task_target = []\n",
    "    task_trial = []\n",
    "    task_fmri_masked = []\n",
    "    combined_task = []\n",
    "    combined_task_trial = []\n",
    "\n",
    "    # Load run 1 to run 4 \n",
    "    for r in range(0,4):                \n",
    "        task_path.append(dir_input + \"/\" + subjID + \"/run\" + str(r+1) + \"_zmap.nii.gz\")        \n",
    "        task_label_path.append(dir_label + \"/\" + subjID  + \"/run\" + str(r+1) + \"_label.txt\")\n",
    "        task_label.append(np.recfromcsv(task_label_path[r], delimiter=\" \"))\n",
    "        task_target.append(task_label[r]['condition'])\n",
    "        task_condition_mask.append(np.logical_or(task_label[r]['condition'] == 1, task_label[r]['condition'] == 2))\n",
    "        task_target[r] = task_target[r][task_condition_mask[r]]\n",
    "        task_trial.append(task_label[r][task_condition_mask[r]])\n",
    "\n",
    "        # Stopped here because of mask issues\n",
    "        task_fmri_masked.append(nifti_masker.fit_transform(task_path[r]))\n",
    "        task_fmri_masked[r] = task_fmri_masked[r][task_condition_mask[r]]\n",
    "\n",
    "    #Concatenate Runs and Labels \n",
    "    combined_task = np.vstack([task_fmri_masked[0],task_fmri_masked[1],task_fmri_masked[2],task_fmri_masked[3]])\n",
    "    combined_task_trial = np.vstack([task_trial[0].tolist(),task_trial[1].tolist(),task_trial[2].tolist(),task_trial[3].tolist()])\n",
    "\n",
    "    # Classify\n",
    "    prob = classifier.predict_proba(combined_task)\n",
    "\n",
    "    # Output to CSV\n",
    "    toPrint = np.column_stack([combined_task_trial,prob[:,1]])\n",
    "    AllShifts = np.vstack([AllShifts,toPrint]);\n",
    "\n",
    "    if not os.path.exists(\"../../results/TrialClassification/\" + design + \"_zmap/TrainTrial/\" + mask_file + \"/\" + classifier_name):\n",
    "        os.makedirs(\"../../results/TrialClassification/\" + design + \"_zmap/TrainTrial/\" + mask_file + \"/\" + classifier_name)\n",
    "\n",
    "    outputfile = \"../../results/TrialClassification/\" + design + \"_zmap/TrainTrial/\" + mask_file + \"/\" + classifier_name + \"/\" + subjID + \".csv\"\n",
    "    np.savetxt(outputfile, AllShifts, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
